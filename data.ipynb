{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38b0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc48ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_unprocessed = Path.cwd() / \"data\" / \"input\" / \"unprocessed\"\n",
    "path_folder_processed = Path.cwd() / \"data\" / \"input\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd60c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = loadmat(path_folder_unprocessed / \"KPG193_ver1_2\" / \"network\" / \"mat\" / \"KPG193_ver1_2.mat\")[\"mpc\"][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4e1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 122\n",
    "num_buses = 197\n",
    "fx_rate = 1000\n",
    "idx_unit_sorted_by_cost_lin = np.argsort(raw[\"gencost\"][:, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee9d56",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6391da",
   "metadata": {},
   "source": [
    "**GENERATION UNITS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edce85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [KPG193] 0: Nuclear, 1: Coal, 2: LNG\n",
    "unit_type = np.array([\n",
    "    1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n",
    "    2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "    0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, \n",
    "    0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
    "], dtype=np.uint64)[idx_unit_sorted_by_cost_lin]\n",
    "idx_nuclear = np.arange(num_units)[unit_type == 0]\n",
    "idx_coal = np.arange(num_units)[unit_type == 1]\n",
    "idx_lng = np.arange(num_units)[unit_type == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d8a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_const, cost_lin = (raw[\"gencost\"][:, [-1, -2]] * fx_rate)[idx_unit_sorted_by_cost_lin].transpose()\n",
    "p_max, p_min = raw[\"gen\"][:, [8, 9]][idx_unit_sorted_by_cost_lin].transpose()\n",
    "(\n",
    "    ramp_up,\n",
    "    ramp_down,\n",
    "    startup_ramp,\n",
    "    shutdown_ramp,\n",
    "    min_up,\n",
    "    min_down,\n",
    ") = raw[\"genthermal\"][:, [5, 6, 7, 8, 1, 2]][idx_unit_sorted_by_cost_lin].transpose()\n",
    "min_up = min_up.astype(np.int64)\n",
    "min_down = min_down.astype(np.int64)\n",
    "# [KPG193] error fix\n",
    "ramp_up[idx_nuclear] = p_min[idx_nuclear]\n",
    "ramp_down[idx_nuclear] = p_min[idx_nuclear]\n",
    "startup_ramp[idx_nuclear] = p_min[idx_nuclear]\n",
    "shutdown_ramp[idx_nuclear] = p_min[idx_nuclear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b1b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_str in (\n",
    "    \"unit_type\",\n",
    "    \"idx_nuclear\",\n",
    "    \"idx_coal\",\n",
    "    \"idx_lng\",\n",
    "    \"cost_const\",\n",
    "    \"cost_lin\",\n",
    "    \"p_max\",\n",
    "    \"p_min\",\n",
    "    \"ramp_up\",\n",
    "    \"ramp_down\",\n",
    "    \"startup_ramp\",\n",
    "    \"shutdown_ramp\",\n",
    "    \"min_up\",\n",
    "    \"min_down\",\n",
    "):\n",
    "    np.save(path_folder_processed / f\"{var_str}.npy\", eval(var_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb195e9",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2718b",
   "metadata": {},
   "source": [
    "**STARTUP COST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3f8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "startup_costs_raw = (raw[\"genthermal\"][:, -6:-3] * fx_rate)[idx_unit_sorted_by_cost_lin]\n",
    "tier_len_raw = raw[\"genthermal\"][:, -3:][idx_unit_sorted_by_cost_lin].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9d0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_startup_step = [startup_costs_raw[i].tolist() for i in range(num_units)]\n",
    "step_length = [tier_len_raw[i].tolist() for i in range(num_units)]\n",
    "\n",
    "np.save(path_folder_processed / \"cost_startup_step.npy\", cost_startup_step)\n",
    "np.save(path_folder_processed / \"step_length.npy\", step_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b340086",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_startup_step_old = []\n",
    "for idx_unit, (cost_startup_pseudo_i, startup_delay_i) in enumerate(zip(\n",
    "    startup_costs_raw,\n",
    "    tier_len_raw\n",
    ")):\n",
    "    \n",
    "    cost_startup_step_old.append(\n",
    "            [float(cost_startup_pseudo_i[0])] * startup_delay_i[0]\n",
    "            + [float(cost_startup_pseudo_i[1])] * (startup_delay_i[1] - startup_delay_i[0])\n",
    "            + [float(cost_startup_pseudo_i[2])] * (startup_delay_i[2] - startup_delay_i[1])\n",
    "        )\n",
    "num_cooling_steps_old = np.array([len(css_i) for css_i in cost_startup_step_old])\n",
    "\n",
    "with open(path_folder_processed / \"cost_startup_step_old.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cost_startup_step_old, f)\n",
    "np.save(path_folder_processed / \"num_cooling_steps_old.npy\", num_cooling_steps_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e3097",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a54e89",
   "metadata": {},
   "source": [
    "**2022 HOURLY TIMESTAMP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f60899",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_2022 = np.arange(np.datetime64(\"2022-01-01T00\"), np.datetime64(\"2023-01-01T00\"))\n",
    "np.save(path_folder_processed / \"timestamp_2022.npy\", timestamp_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8e5a6",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0697a",
   "metadata": {},
   "source": [
    "**2022 HOURLY DEMAND** (KPX == KPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b13c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demand_2022():\n",
    "    demand_2022 = np.empty((365, 24, num_buses))\n",
    "    path_folder_per_bus_demand = path_folder_unprocessed / \"KPG193_ver1_2\" / \"profile\" / \"demand\"\n",
    "    \n",
    "    for day in range(365):\n",
    "        demand_2022[day] = (\n",
    "            pd.read_csv(path_folder_per_bus_demand / f\"daily_demand_{day + 1}.csv\")\n",
    "            .drop(columns=\"demandQ\")\n",
    "            .sort_values(by=[\"hour\", \"bus_id\"])\n",
    "            [[\"demandP\"]]\n",
    "            .values\n",
    "            .reshape((24, num_buses))\n",
    "        )\n",
    "\n",
    "    return demand_2022.reshape((8760, num_buses)).sum(axis=1)\n",
    "\n",
    "demand_2022 = get_demand_2022()\n",
    "np.save(path_folder_processed / \"demand_2022.npy\", demand_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe71786",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42c98a",
   "metadata": {},
   "source": [
    "**2022 HOURLY STATUS** (KPG SPECIFIC TO KPG RENEWABLE) (NOT USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad175009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status_2022():\n",
    "    status_2022 = np.empty((365, 24, num_units), dtype=np.int64)\n",
    "    path_folder_per_unit_status = path_folder_unprocessed / \"KPG193_ver1_2\" / \"profile\" / \"commitment_decision\"\n",
    "\n",
    "    for day in range(365):\n",
    "        status_2022[day] = (\n",
    "            pd.read_csv(path_folder_per_unit_status / f\"commitment_decision_{day + 1}.csv\")\n",
    "            .sort_values(by=[\"hour\", \"generator_id\"])\n",
    "            [[\"status\"]]\n",
    "            .values\n",
    "            .reshape((24, num_units))\n",
    "        )\n",
    "\n",
    "    return status_2022.reshape((8760, num_units)).transpose()[idx_unit_sorted_by_cost_lin]\n",
    "\n",
    "status_2022 = get_status_2022()\n",
    "# np.save(path_folder_processed / \"status_2022.npy\", status_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484fa03",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96702ebf",
   "metadata": {},
   "source": [
    "**2022 HOURLY MUST-OFFS** (KPG SPECIFIC TO KPG RENEWABLE) (NOT USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3136ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_must_off_2022():\n",
    "    mustoff_2022 = pd.read_csv(path_folder_unprocessed / \"KPG193_ver1_2\" / \"mustoff\" / \"nuclear_mustoff.csv\").to_numpy()\n",
    "\n",
    "    # [KPG193] mustoff 'off_end_day' exceeding 365\n",
    "    mask_exceed_365 = mustoff_2022[:, 3] > 365\n",
    "    mustoff_2022[:, 3][mask_exceed_365] = 365\n",
    "    mustoff_2022[:, 4][mask_exceed_365] = 24\n",
    "\n",
    "    mustoff_2022 -= 1 # 0-based indexing bus and time\n",
    "    mustoff_2022[:, 1] = mustoff_2022[:, 1] * 24 + mustoff_2022[:, 2]\n",
    "    mustoff_2022[:, 2] = mustoff_2022[:, 3] * 24 + mustoff_2022[:, 4]\n",
    "\n",
    "    return mustoff_2022[:, :3] # unit; mustoff_start; mustoff_end\n",
    "\n",
    "mustoff_2022 = get_must_off_2022()\n",
    "# np.save(path_folder_processed / \"mustoff_2022.npy\", mustoff_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17168498",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125f92d",
   "metadata": {},
   "source": [
    "**2022 HOURLY RENEWABLE** (KPG SPECIFIC) (NOT USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_renewable_ratio_2022():\n",
    "    solar_ratio_2022, wind_ratio_2022, hydro_ratio_2022 = np.empty((365, 24, num_buses)), np.empty((365, 24, num_buses)), np.empty((365, 24, num_buses))\n",
    "    path_folder_reg_profile = path_folder_unprocessed / \"KPG193_ver1_2\" / \"profile\" / \"renewables\"\n",
    "    \n",
    "    for day in range(365):\n",
    "\n",
    "        df = (\n",
    "            pd.read_csv(path_folder_reg_profile / f\"renewables_{day + 1}.csv\")\n",
    "            # [KPG193] random CSV nans\n",
    "            .fillna(0)\n",
    "            # [KPG193] missing bus 151, duplicate 153 lines for 24 hours\n",
    "            .assign(bus_id=lambda d: d.bus_id.where(d.bus_id != 152, 151))\n",
    "            .pipe(lambda d: pd.concat(\n",
    "                [\n",
    "                    d[d.bus_id != 153],\n",
    "                    (\n",
    "                        d\n",
    "                        .query(\"bus_id == 153\")\n",
    "                        .drop_duplicates(\"hour\")\n",
    "                        .pipe(lambda x: pd.concat([x.assign(bus_id=152),x.assign(bus_id=153)]))\n",
    "                    )\n",
    "                ],\n",
    "                ignore_index=True\n",
    "            ))\n",
    "            .sort_values([\"hour\", \"bus_id\"])\n",
    "        )\n",
    "\n",
    "        solar_ratio_2022[day] = df.pv_profile_ratio.values.reshape(24, num_buses)\n",
    "        wind_ratio_2022[day] = df.wind_profile_ratio.values.reshape(24, num_buses)\n",
    "        hydro_ratio_2022[day] = df.hydro_profile_ratio.values.reshape(24, num_buses)\n",
    "\n",
    "    return solar_ratio_2022.reshape((8760, num_buses)), wind_ratio_2022.reshape((8760, num_buses)), hydro_ratio_2022.reshape((8760, num_buses))\n",
    "\n",
    "\n",
    "def get_renewable_capacity_2022():\n",
    "    # [KPG193] 4 missing buses in solar and hydro\n",
    "    solar_capacity_2022, wind_capacity_2022, hydro_capacity_2022 = np.zeros(num_buses), np.zeros(num_buses), np.zeros(num_buses)\n",
    "    path_folder_reg_capacity = path_folder_unprocessed / \"KPG193_ver1_2\" / \"renewables_capacity\"\n",
    "    reg_dict = {\"solar\": solar_capacity_2022, \"wind\": wind_capacity_2022, \"hydro\": hydro_capacity_2022}\n",
    "\n",
    "    for reg_str, reg_var in reg_dict.items():\n",
    "        raw = (\n",
    "            pd.read_csv(path_folder_reg_capacity / f\"{reg_str}_generators_2022.csv\")\n",
    "            # [KPG193] random CSV nans\n",
    "            .fillna(0)\n",
    "            [[\"bus_ID\", \"Pmax [MW]\"]]\n",
    "        )\n",
    "        # [KPG193] 4 missing buses in solar and hydro\n",
    "        reg_var[raw[\"bus_ID\"].values - 1] = raw[\"Pmax [MW]\"].values \n",
    "    \n",
    "    return solar_capacity_2022, wind_capacity_2022, hydro_capacity_2022\n",
    "\n",
    "\n",
    "solar_ratio_2022_kpg, wind_ratio_2022_kpg, hydro_ratio_2022_kpg = get_renewable_ratio_2022()\n",
    "solar_cap_2022_kpg, wind_cap_2022_kpg, hydro_cap_2022_kpg = get_renewable_capacity_2022()\n",
    "\n",
    "# # # all renewable sources \n",
    "# solar_gen_2022_kpg, wind_gen_2022_kpg, hydro_gen_2022_kpg = solar_ratio_2022_kpg * solar_cap_2022_kpg, wind_ratio_2022_kpg * wind_cap_2022_kpg, hydro_ratio_2022_kpg * hydro_cap_2022_kpg\n",
    "# renewable_gen_2022_kpg = (solar_gen_2022_kpg + wind_gen_2022_kpg + hydro_gen_2022_kpg).sum(axis=1)\n",
    "# np.save(path_folder_processed / \"renewable_gen_2022_kpg.npy\", renewable_gen_2022_kpg)\n",
    "\n",
    "# renewable_cap_2022_kpg = solar_cap_2022_kpg.sum() + wind_cap_2022_kpg.sum() + hydro_cap_2022_kpg.sum() # each arr is per-bus cap\n",
    "# renewable_cap_2022_kpg = np.full((8760), renewable_cap_2022_kpg) # its just same for the whole year # 32.588 GW\n",
    "# np.save(path_folder_processed / \"renewable_cap_2022_kpg.npy\", renewable_cap_2022_kpg)\n",
    "\n",
    "# renewable_ratio_2022_kpg = renewable_gen_2022_kpg / renewable_cap_2022_kpg\n",
    "# np.save(path_folder_processed / \"renewable_ratio_2022_kpg.npy\", renewable_ratio_2022_kpg)\n",
    "\n",
    "# only solar (maybe for comparison with KPX)\n",
    "# solar_gen_2022_kpg = (solar_ratio_2022_kpg * solar_cap_2022_kpg).sum(axis=1)\n",
    "# np.save(path_folder_processed / \"solar_gen_2022_kpg.npy\", solar_gen_2022_kpg)\n",
    "\n",
    "# solar_cap_2022_kpg = np.full((8760), solar_cap_2022_kpg.sum())\n",
    "# np.save(path_folder_processed / \"solar_cap_2022_kpg.npy\", solar_cap_2022_kpg)\n",
    "\n",
    "# solar_ratio_2022_kpg = solar_gen_2022_kpg / solar_cap_2022_kpg\n",
    "# np.save(path_folder_processed / \"solar_ratio_2022_kpg.npy\", solar_ratio_2022_kpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf738989",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1e88a",
   "metadata": {},
   "source": [
    "**2022 HOURLY RENEWABLE** (KPX SPECIFIC) (USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_folder_unprocessed / \"historical_renewable\" / \"한국전력거래소_신재생 발전량 및 설비용량_20221231.csv\", encoding=\"cp949\")\n",
    "\n",
    "# df = (\n",
    "#     df.groupby([\"거래일자\", \"거래시간\"], as_index=False)\n",
    "#       [[\"설비용량(MW)\", \"전력거래량(MWh)\"]]\n",
    "#       .sum()\n",
    "# )\n",
    "# renewable_cap_2022 = df[\"설비용량(MW)\"].values\n",
    "# renewable_gen_2022 = df[\"전력거래량(MWh)\"].values\n",
    "\n",
    "# I'm only going to consider solar cus i can't do demand distribution + solar + wind + ... multiple distribution like this \n",
    "# just 2 distribution. i don't have time and i don't even think triple p distribution could be done in one semester too\n",
    "df = df[df[\"원료원\"] == \"태양광\"]\n",
    "df = (\n",
    "    df.groupby([\"거래일자\", \"거래시간\"], as_index=False)\n",
    "      [[\"설비용량(MW)\", \"전력거래량(MWh)\"]]\n",
    "      .sum()\n",
    ")\n",
    "renewable_cap_2022 = df[\"설비용량(MW)\"].values\n",
    "renewable_gen_2022 = df[\"전력거래량(MWh)\"].values\n",
    "renewable_ratio_2022 = renewable_gen_2022 / renewable_cap_2022\n",
    "np.save(path_folder_processed / \"renewable_cap_2022.npy\", renewable_cap_2022)\n",
    "np.save(path_folder_processed / \"renewable_gen_2022.npy\", renewable_gen_2022)\n",
    "np.save(path_folder_processed / \"renewable_ratio_2022.npy\", renewable_ratio_2022)\n",
    "# discussion of modelling issue with the use of KPG renewable + status data\n",
    "# I'm probably gonna have to briefly discuss the \"\"\"Deviation\"\"\" from the reality due to this (or just how might >2-distr. result might look like)\n",
    "# (although SMP itself is just linear cost not the \"\"\"avg. fuel cost\"\"\" that KPX uses and reality gap ins't even the goal of this project)\n",
    "# either way using KPG renewable + KPG status / KPX renewable + my own status, it was much farther away from reality bc reneable was too much in KPG\n",
    "# with KPG renewable it does NOT make sense NOT TO include curtailment which is not the goal of this project\n",
    "# last and most importantly, historical renewable should be used for question 3 analysis\n",
    "# idk how other teams just went on with this or any of the stuffs i've done but anyways i think this is just something so basic and can't be ignored for accuracy of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2967b",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9e513",
   "metadata": {},
   "source": [
    "**2019 ~ 2022 HISTORICAL RENEWABLE AND DEMAND** (KPX) (USED FOR Q3) (LEAP DAY IN 2020 = 2020-09-28 REMOVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d7e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv(path_folder_unprocessed / \"historical_renewable\" / \"한국전력거래소_신재생 발전량 및 설비용량_20221231.csv\", encoding=\"cp949\")\n",
    "df_2022 = df_2022[df_2022[\"원료원\"] == \"태양광\"]\n",
    "\n",
    "df = pd.read_csv(path_folder_unprocessed / \"historical_renewable\" / \"2019_2021년 신재생에너지 시간대별 연료원별 거래량 및 설비용량.csv\", encoding=\"cp949\")\n",
    "df = df[df[\"연료원구분\"] == \"태양광\"]\n",
    "df = (\n",
    "    df.groupby([\"거래일자\", \"거래시간\"], as_index=False)\n",
    "      [[df.columns[-2], df.columns[-1]]]\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "# as an enginnering undergraudate i just removed the leap date in 2022\n",
    "timestamp_temp = df[\"거래일자\"].values.astype(\"datetime64\") + (df[\"거래시간\"].values.astype(\"timedelta64[h]\") - np.timedelta64(1, \"h\"))\n",
    "\n",
    "idx_leap_date_start = np.where(timestamp_temp == np.datetime64(\"2020-02-29T00\"))[0][0]\n",
    "\n",
    "timestamp_hist = np.concatenate((\n",
    "    timestamp_temp[:idx_leap_date_start], \n",
    "    timestamp_temp[idx_leap_date_start + 23 + 1:],\n",
    "    np.arange(\n",
    "        np.datetime64(\"2022-01-01T00\"),\n",
    "        np.datetime64(\"2023-01-01T00\"),\n",
    "    )\n",
    "))\n",
    "\n",
    "renewable_cap_temp, renewable_gen_temp = df[\"설비용량(MW)\"].values, df[df.columns[-1]].values\n",
    "renewable_cap_hist = np.concatenate((\n",
    "    renewable_cap_temp[:idx_leap_date_start],\n",
    "    renewable_cap_temp[idx_leap_date_start + 23 + 1:],\n",
    "    renewable_cap_2022\n",
    "))\n",
    "renewable_gen_hist = np.concatenate((\n",
    "    renewable_gen_temp[:idx_leap_date_start],\n",
    "    renewable_gen_temp[idx_leap_date_start + 23 + 1:],\n",
    "    renewable_gen_2022,\n",
    "))\n",
    "renewable_ratio_hist = renewable_gen_hist / renewable_cap_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "095ebae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_folder_unprocessed / \"historical_demand\" / \"2013~2020 수요관리후 발전단 전력수요실적.csv\", encoding=\"cp949\")\n",
    "demand_hist = df[(df[\"날짜\"] >= \"2019-01-01\") & (df[\"날짜\"] != \"2020-02-29\")].to_numpy()[:, 1:].reshape(-1,).astype(float)\n",
    "df = pd.read_csv(path_folder_unprocessed / \"historical_demand\" / \"2021년 1_12월 수요관리후 발전단 수요실적.csv\", encoding=\"cp949\")\n",
    "demand_hist = np.concatenate((demand_hist, df.to_numpy()[:, 1:].reshape(-1).astype(float), demand_2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f05cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_folder_processed / \"timestamp_hist.npy\", timestamp_hist)\n",
    "np.save(path_folder_processed / \"renewsable_cap_hist.npy\", renewable_cap_hist)\n",
    "np.save(path_folder_processed / \"renewable_gen_hist.npy\", renewable_gen_hist)\n",
    "np.save(path_folder_processed / \"renewable_ratio_hist.npy\", renewable_ratio_hist)\n",
    "np.save(path_folder_processed / \"demand_hist.npy\", demand_hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
